{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de Grafos / Redes Sociales: Kevin Bacon\n",
    "[https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon#Bacon_numbers](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon#Bacon_numbers)\n",
    "\n",
    "You are given a network of actors, where there is an edge between two actors if they have played together in some movie between 1995 and 2004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una primer mirada a los data sets que vamos a utilizar\n",
    "\n",
    "Tenemos dos data sets:\n",
    "\n",
    "- **imdb_actors_key_noheader.tsv:** Informacion sobre los actores (id, nombre, cantidad de peliculas actuadas, generos por peliculas, etc).\n",
    "- **imdb_actor_edges.tsv:** Network propiamente dicha (relaciones de actor a actor por id y cantidad de veces que actuaron juntos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de raw data\n",
    "# tsv: tab separated value\n",
    "actors = sc.textFile('data/imdb_actors_key_noheader.tsv', 8)\n",
    "print('Cantidad de Actores:')\n",
    "print(actors.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizas splits de las tuplas por \\t (tab)\n",
    "actors.map(lambda x: tuple(x.split('\\t')))\\\n",
    "      .take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la red tiene nodos de la forma (actor1, actor2, veces_que_actuaron_juntos)\n",
    "network = sc.textFile('data/imdb_actor_edges.tsv')\n",
    "print('Cantidad de Aristas/Edges:')\n",
    "print(network.count())\n",
    "\n",
    "network.map(lambda x: tuple(x.split('\\t')))\\\n",
    "      .take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializando los RDDs\n",
    "\n",
    "Vamos a inicializar los RDDs que utilizaremos\n",
    "\n",
    "**Nota** Dado que estaremos usando estos RDDs en muchos casos de forma iterativa, realizaremos la operacion ``.cache()`` sobre los mismos, asegurandonos de que esa forma una vez que es calculado al haberse aplicado una accion cada nodo mantenga en memoria la particion que calculo.\n",
    "\n",
    "Esto es importante al realizar algoritmos iterativos, dado que permite hasta una mejora de velocidad de 10x.\n",
    "\n",
    "Para mas referencia: [https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence](https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializamos algunos rdds que vamos a utilizar en conjunto con nuestro network\n",
    "\n",
    "# de la informacion de actores nos quedamos con su identificados y nombre\n",
    "actors_key = actors.map(lambda x: tuple(x.split('\\t')))\\\n",
    "                    .map(lambda x:(int(x[0]),x[1]))\\\n",
    "                    .cache()\n",
    "\n",
    "actors_key_cat = actors.map(lambda x: tuple(x.split('\\t')))\\\n",
    "                    .map(lambda x:(int(x[0]),(x[1],x[3])))\\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actors_key_cat tiene nodos de la forma (actor_id, nombre_actor)\n",
    "print(\"Ejemplo de actores de actors_key:\")\n",
    "print(actors_key.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actors_key_cat tiene nodos de la forma (actor_id, (nombre_actor, nombre_categoria_mas_frecuente))\n",
    "print(\"Ejemplo de actores de actors_key_cat:\")\n",
    "print(actors_key_cat.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que podamos realizar algo con todos esto :)\n",
    "KEVIN_BACON_ID=3257\n",
    "kevin = actors_key_cat.filter(lambda x:x[0]==KEVIN_BACON_ID)\n",
    "print(\"Nuestro Heroe:\")\n",
    "print(kevin.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializamos el RDD de la network\n",
    "network = sc.textFile('data/imdb_actor_edges.tsv')\n",
    "print(network.count())\n",
    "network = network.map(lambda x:tuple(x.split('\\t')))\\\n",
    "                 .map(lambda x:(int(x[0]),int(x[1]),int(x[2])))\\\n",
    "                 .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network tiene nodos de la forma (actor1, actor2, cantidad_de_veces_que_actuaron_juntos)\n",
    "print(\"Ejemplo de 5 tuplas del network RDD:\")\n",
    "print(network.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructuras para un Grafo\n",
    "\n",
    "Las representacion posibles que tenemos son:\n",
    "\n",
    "- **Lista de Aristas**\n",
    "    - Una tupla por arista del tipo (nodo1, nodo2).\n",
    "    - Puede incluir algun otro tipo de informacion relevante para la relacion.\n",
    "- **Lista de Adyacencias**\n",
    "    - Una tupla por nodo del tipo (nodo, [lista de vecinos])\n",
    "    \n",
    "    \n",
    "Inicialmente trabajaremos con el grafo como una lista de aristas, luego para atacar otros problemas trabajaremos en spark con una lista de adyacencias.\n",
    "\n",
    "Sin embargo podemos ver alguna informacion interesante respecto al grafo con el que estaremos trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad Nodos (Actores): ' + str(actors_key.count()))\n",
    "print('Cantidad de Aristas (Conexiones): ' + str(network.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizando Algunas propiedades de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuales son los generos posibles\n",
    "actors_key_cat.map(lambda x: x[1][1])\\\n",
    "              .distinct()\\\n",
    "              .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuantas personas tenemos por generos posibles\n",
    "actors_per_usual_category = actors_key_cat.map(lambda x: (x[1][1],1))\\\n",
    "                                          .reduceByKey(lambda x,y: x+y)\\\n",
    "                                          .collect();\n",
    "\n",
    "for actor in actors_per_usual_category:\n",
    "    print(str(actor[0]) + ' ' + str(actor[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 actores que trabajaron con a mayor cantidad de personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = network.flatMap(lambda x:[(x[0],1),(x[1],1)])\n",
    "mn = mn.reduceByKey(lambda x,y:x+y)\n",
    "mn = mn.join(actors_key_cat)\n",
    "#mn = mn.filter(lambda x: x[1][1][1] != 'Adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_actors = mn.takeOrdered(10,lambda x:-x[1][0])\n",
    "for actor in top_actors:\n",
    "    print(actor[1][1][0]+'('+str(actor[1][0]) + ' personas) Genero:' + str(actor[1][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que pasa con Kevin Bacon?\n",
    "bm = mn.filter(lambda x:x[0]==KEVIN_BACON_ID).take(1)\n",
    "print(\"Kevin Bacon trabajo con \" + str(bm[0][1][0]) + \" personas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Degree of Kevin Bacon\n",
    "\n",
    "Queremos conocer las personas que se encuentra a un grado de separacion de Kevin Bacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtramos aquellos aristas que tengan a kevin bacon\n",
    "kevin1 = network.filter(lambda x:x[0]==KEVIN_BACON_ID or x[1]==KEVIN_BACON_ID)\n",
    "# emitimos aquellos actor_id de los actores que trabajaron con Kevin\n",
    "kevin1 = kevin1.map(lambda x:x[0] if x[1]==KEVIN_BACON_ID else x[1])\n",
    "print(kevin1.collect())\n",
    "print(\"Actors a 1 grado de separacion de Kevin Bacon: \" + str(kevin1.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenemos los nombres de los actores a un grado de separacion.\n",
    "kevin1_names = kevin1.map(lambda x:(x,1))\\\n",
    "                     .join(actors_key)\\\n",
    "                     .map(lambda x:x[1][1])\n",
    "\n",
    "bacon1_actors = kevin1_names.collect()\n",
    "for actor in bacon1_actors:\n",
    "    print(actor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grado Promedio de la Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_deg = network.flatMap(lambda x:[(x[0],1),(x[1],1)])\\\n",
    "                   .reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "num_actors = total_deg.count()\n",
    "\n",
    "print(\"Numero total de actores: \" + str(num_actors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum_deg = total_deg.map(lambda x:x[1]).reduce(lambda x,y: x+y)\n",
    "\n",
    "print(\"Grado Promedio: \" + str((float(acum_deg)/num_actors)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Degrees of Kevin Bacon\n",
    "\n",
    "Para poder realizar el calculo de los N-Degrees de Kevin Bacon (conocidos como Bacon Numbers) realizaremos una implementacion distribuida de BFS.\n",
    "\n",
    "Para poder realizar la implementacion de N-Degrees of Kevin Bacon vamos a necesitar convertirlo en lista de adyacencia, \n",
    "\n",
    "```\n",
    "(A,B)(A,C)(B,C) a una representacion del tipo (A,[B,C]),(B,[C]).\n",
    "```\n",
    "\n",
    "Pero en particular para implementar algoritmos de camino minimos con un formato particular.\n",
    "\n",
    "```\n",
    "(node_id, (distance, status, [list of neighbors], trace))\n",
    "```\n",
    "\n",
    "En el caso particular para calcular los Bacon Numbers vamos a usar la siguiente representacion:\n",
    "\n",
    "```\n",
    "[(node_id,(distance_from_kevin,status,[neighbors], trace)),....(node,(distance_from_kevin,status,[neighbors], trace))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convirtiendo el grafo en lista de adyacencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# First we convert each (A,B) into (A,B) and (B,A)\n",
    "adjlist = network.flatMap(lambda x:[(x[0],x[1]),(x[1],x[0])])\n",
    "\n",
    "# veamos especificamente que pasa con Kevin Bacon\n",
    "# uso de set para evitar duplicados, etc.\n",
    "kadj = adjlist.groupByKey()\\\n",
    "             .filter(lambda x:x[0]==KEVIN_BACON_ID)\\\n",
    "             .map(lambda x:(x[0],(set(x[1]))))\n",
    "\n",
    "kadj_driver = kadj.take(1)\n",
    "\n",
    "print(kadj_driver)\n",
    "\n",
    "print('Cantidad de vecinos de Kevin Bacon: ' + str(len(kadj_driver[0][1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llevando a la representacion necesaria para calcular los Bacon Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando groupByKey tenemos toda la informacion para poder armar la lista de adyacencia\n",
    "# usando un set oara eliminar los duplicados.\n",
    "# Inicializamos la distancia como infinito con 999\n",
    "# status en -\n",
    "# la lista de vecinos de ese nodo\n",
    "# trace en 0\n",
    "adjlist = adjlist.groupByKey()\\\n",
    "                 .map(lambda x:(x[0],(999,'-',list(set(x[1])),0)))\\\n",
    "                 .cache()\n",
    "\n",
    "total_nodes = adjlist.count()\n",
    "print(\"Numero total de nodos en nuestro grafo: \" + str(total_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuestro RDD ahora tiene la forma [(node,(distance_from_kevin,status,[neighbors], trace)),....(node,(distance_from_kevin,status,[neighbors], trace))]\n",
    "print adjlist.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El siguiente paso es marcar todos los nodos que son vecinos de Kevin Bacon como: \n",
    "#    1. a distancia 1\n",
    "#    2. y como procesados en el status con 'P'\n",
    "# Para hacer esto tomamos el nodo de Kevin Bacon y generamos nuevos nodos para los vecinos de la forma\n",
    "# (node_id,(1,'P',[])).\n",
    "# Luego en la fase de reduceByKey vamos a hacer un join de todos los nodos en uno unico (esperemos!)\n",
    "\n",
    "# Para hacer esto definimos la funcion proc_node como la funcion que procesa un nodo \n",
    "# y vamos a comenzar el procesamiento desde KEVIN_BACON_ID (Kevin Bacon)\n",
    "def proc_node(node):\n",
    "    # Recibimos un nodo de la forma (nodeid, distance_from_kevin, status, list_of_neighbors, trace)\n",
    "    # Generamos nuevos nodos para cada vecino agregando 1 a la distancia del nodo actual (!)\n",
    "    if node[1][0]==999:\n",
    "        new_distance = 1\n",
    "    else:\n",
    "        new_distance = node[1][0]+1\n",
    "    ret = []\n",
    "    for neighbor in node[1][2]:\n",
    "        ret.append((neighbor,(new_distance,'P',[],node[0])))\n",
    "    # We also update the node as already processed!\n",
    "    ret.append((node[0],(node[1][0],'DONE',node[1][2],node[1][3])))\n",
    "    return ret\n",
    "\n",
    "# Definimos la funcion de reduccion\n",
    "def reduce_nodes(n1,n2):\n",
    "    # Recibimos dos nodos de la forma (distance_from_kevin,status,list_of_neighbors,trace) \n",
    "    # No quedamos con la distancia minima\n",
    "    # si uno de los nodos esta marcado como 'DONE' nos quedamos con 'DONE'\n",
    "    # si uno de los nodos esta marcado como 'P' nos quedamos con 'P'\n",
    "    # nos quedamos con la lista mas larga de vecinos (alguna podria estar vacia)\n",
    "    # Mantenemos un trace de la minima distancia\n",
    "    new_status = ''\n",
    "    if n1[1]=='P' or n2[1]=='P':\n",
    "        new_status = 'P'\n",
    "    if n1[1]=='DONE' or n2[1]=='DONE':\n",
    "        new_status = 'DONE'\n",
    "    if n1[0]<n2[0]:\n",
    "        new_distance = n1[0]\n",
    "        trace = n1[3]\n",
    "    else:\n",
    "        new_distance = n2[0]\n",
    "        trace = n2[3]\n",
    "    new_list = n1[2]\n",
    "    if len(n2[2])>len(n1[2]):\n",
    "        new_list = n2[2]\n",
    "    return (new_distance,new_status,new_list,trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera Pasada\n",
    "\n",
    "Procesamos inicialmente solo el nodo de Kevin Bacon. Luego de esta Primera pasada deberiamos obtener solamente 101 con Bacon Numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera Pasada: Nuestra primer tarea es procesar solo el nodo de Kevin Bacon (KEVIN_BACON_ID)\n",
    "adjlist = adjlist.flatMap(lambda x:proc_node(x) if x[0]==KEVIN_BACON_ID else [x])\n",
    "adjlist = adjlist.reduceByKey(reduce_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos cuantos luego de la primer pasada tienen el bacon number\n",
    "# estos serian los que estan a un grado de separacion\n",
    "# y por lo que comprobamos anteriormente deberian ser 101\n",
    "def bn_stats(adjlist,total_nodes):\n",
    "    k_with_number = adjlist.filter(lambda x:x[1][0]<999)\n",
    "    print(\"Numero de nodos con Bacon Number: \" + str(k_with_number.count()) + \"/\" + str(total_nodes))\n",
    "\n",
    "bn_stats(adjlist,total_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_with_bacon_numbers(adjlist, degree): \n",
    "    print(\"Algunos Actores with Bacon Numbers\")\n",
    "    kb_1_names = adjlist.filter(lambda x:x[1][0]==degree)\\\n",
    "                         .map(lambda x:(x[0],1))\\\n",
    "                         .join(actors_key)\\\n",
    "                         .map(lambda x:x[1][1])\\\n",
    "\n",
    "    for name in kb_1_names.take(20):\n",
    "        print(name)\n",
    "\n",
    "some_with_bacon_numbers(adjlist,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda Pasada\n",
    "\n",
    "Nuestro segundo paso consiste en procesar todos aquellos nodos con status 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuestro siguiente paso consiste en procesar todos los nodos con status 'P'\n",
    "adjlist = adjlist.flatMap(lambda x:proc_node(x) if x[1][1]=='P' else [x])\n",
    "adjlist = adjlist.reduceByKey(reduce_nodes)\n",
    "\n",
    "bn_stats(adjlist,total_nodes)\n",
    "some_with_bacon_numbers(adjlist,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siguientes N-Pasadas Iterativas\n",
    "\n",
    "Seguimos procesando entonces los nodos que estan en status 'P' hasta que no queden mas por procesar o no puedan procesarse mas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    adjlist = adjlist.flatMap(lambda x:proc_node(x) if x[1][1]=='P' else [x])\n",
    "    adjlist = adjlist.reduceByKey(reduce_nodes)\n",
    "    bn_stats(adjlist, total_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunas verificaciones notables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Francella, Guillermo (5222)\n",
    "print(adjlist.filter(lambda x:x[0]==5222).join(actors_key_cat).map(lambda x: (x[0],x[1][1][0],x[1][0][0])).collect())\n",
    "# Luis Brandoni (5223)\n",
    "print(adjlist.filter(lambda x:x[0]==5224).join(actors_key_cat).map(lambda x: (x[0],x[1][1][0],x[1][0][0])).collect())\n",
    "# Gaston Pauls (4763)\n",
    "print(adjlist.filter(lambda x:x[0]==4763).join(actors_key_cat).map(lambda x: (x[0],x[1][1][0],x[1][0][0])).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen: Caminos minimos desde un nodo\n",
    "\n",
    "- **Usamos una estructura de nodo de lista de adyacencia con algunas variables extras para ayudar al procesamiento.**\n",
    "    - (node_id, (distance, status, [list of neighbors]))\n",
    "- **El estado inicial es solo con el nodo inicio en status ‘P’ y distancia 0.**\n",
    "- **El resto de los nodos status ‘-’ y distancia Infinita (999) con nodos que vamos a tener que procesar.**\n",
    "- El algoritmo es iterativo, por lo que en cada iteracion hacemos:\n",
    "    - Por cada nodo marcado como 'P' procesamos sus vecinos\n",
    "    - Por cada vecino generamos un nuevo nodo de la forma (node_id, (distance+1,'P',[]))\n",
    "    - Luego en la fase de reduce nos quedaremos la distancia mínima y la lista de vecinos (alguno de los nodos la tiene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walks\n",
    "\n",
    "Concepto a ser desarrollado mas adelante en la materia, en particular para comprender PageRank (Teletransportacion!).\n",
    "\n",
    "**Idea Base: Comenzar en uno o varios nodos al azar y en cada paso movernos a un nodo vecino de forma aleatoria.**\n",
    "\n",
    "Los random walks tienen muchísimas aplicaciones.\n",
    "\n",
    "- Determinar la centralidad (importancia) de nodos o aristas\n",
    "- Encontrar nodos parecidos a otros\n",
    "- Detectar clusters / comunidades\n",
    "- Sistemas de Recomendaciones\n",
    "\n",
    "### En Spark\n",
    "\n",
    "Comenzar con un conjunto de nodos al azar.\n",
    "\n",
    "- Por cada nodo elegir un vecino al azar y agregarlo a los resultados.\n",
    "- Repetir este proceso “n” veces (longitud de los Random Walks)\n",
    "- Observación: La cantidad de random walks es constante pero cada random walk tiene un nodo nuevo en cada iteración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralidad (Importancia) de Nodos Utilizando Random Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrality by Random Walks!\n",
    "# Select some random nodes from the graph\n",
    "# From those nodes start a random walk\n",
    "# Then just compute 1 for each node we have found!\n",
    "import numpy as np\n",
    "\n",
    "# llevamos la representacion que usamos para los bacon numbers \n",
    "# a una tipica representacion de lista de adyacencia\n",
    "graph = network.flatMap(lambda x:[(x[0],x[1]),(x[1],x[0])])\\\n",
    "               .groupByKey()\\\n",
    "               .map(lambda x: (x[0], list(set(x[1]))))\\\n",
    "               .cache()\n",
    "graph.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como primer paso tomamos una muestra aleatoria con reemplazo\n",
    "my_sample = graph.sample(True,0.3)\n",
    "\n",
    "# todos los nodos seleccionados son parte de los random walks\n",
    "all_the_nodes = my_sample.map(lambda x:(x[0],1))\n",
    "\n",
    "print(\"Tomamos una muestra de: \"+ str(my_sample.count()) + \" nodos\")\n",
    "\n",
    "# Esta funcion toma un nodo y retorna un nuevo nodo seleccionando un random neighbor\n",
    "# De cada nodo en la muestra seleccionar un random neighbor\n",
    "def pick_random_neighbor(node):\n",
    "    neighbor = np.random.choice(node[1])\n",
    "    return (neighbor,'node')\n",
    "\n",
    "for i in range(0,50):\n",
    "    # Seleccionar un random neighbor de cada nodo\n",
    "    my_sample = my_sample.map(lambda x:pick_random_neighbor(x)).cache()\n",
    "    # hace un join con grafo para obtener una lista de vecinos\n",
    "    my_sample = my_sample.join(graph).map(lambda x:(x[0],x[1][1])).cache()\n",
    "    # adicionar lo nuevos nodos a la lista de nodos visitados\n",
    "    just_nodes = my_sample.map(lambda x:(x[0],1))\n",
    "    all_the_nodes = all_the_nodes.union(just_nodes).cache()\n",
    "    print(\"Round: \"+str(i)+\" Total number of nodes:\"+str(all_the_nodes.count()))\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "all_the_nodes = all_the_nodes.reduceByKey(lambda x,y:x+y)\n",
    "nodes_with_names = all_the_nodes.join(actors_key_cat)\n",
    "#print nodes_with_names.take(5)\n",
    "central_actors =  nodes_with_names.takeOrdered(50,lambda x:-x[1][0])\n",
    "i=0\n",
    "for actor in central_actors:\n",
    "    i=i+1\n",
    "    print(str(i)+\". \"+actor[1][1][0]+\" (\"+actor[1][1][1]+\") = \"+str(actor[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
